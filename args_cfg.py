import argparse

def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--graph_type', type=str, default='Grid_Graph', help='Grid_Graph, SG_Graph, SY_Graph, SF_Graph')
    parser.add_argument('--time_horizon', type=int, default=6, help='time horizon of the game')
    parser.add_argument('--state_emb_dim', type=int, default=16, help='state embedding dims')
    parser.add_argument('--batch_size', type=int, default=256, help='batch_size')
    parser.add_argument('--node_feat_dim', type=int, default=3, help='feature dims of a node in GNN')
    parser.add_argument('--max_epoch', type=int, default=2000, help='number of GNN pre-pretrain epochs')
    parser.add_argument('--gnn_hidden_dim', type=int, default=128, help='hidden dim of GNN')
    parser.add_argument('--gnn_output_dim', type=int, default=32, help='output dim of GNN')
    parser.add_argument('--gnn_num_layer', type=int, default=2, help='hidden dim of GNN')
    parser.add_argument('--gnn_dropout', type=float, default=0.5, help='dropout rate of GNN')
    parser.add_argument('--hidden_size', type=int, default=128, help='hidden dim of policy or value network')
    parser.add_argument('--seed', type=int, default=101, help='random seed')
    parser.add_argument('--device', type=int, default=0, help='gpu id')
    parser.add_argument('--sf_sw_node_num', type=int, default=300, help='node number of sf or sw map')
    parser.add_argument('--seed_to_generate_graph', type=int, default=100, help='seed to generate sf or sw map')
    parser.add_argument('--row', type=int, default=10, help='row for grid map')
    parser.add_argument('--column', type=int, default=10, help='column for grid map')
    parser.add_argument('--num_defender', type=int, default=5, help='number of pursuers')
    parser.add_argument('--num_exit', type=int, default=8, help='number of exit nodes')
    parser.add_argument('--min_time_horizon', type=int, default=6, help='min time horizon')
    parser.add_argument('--max_time_horizon', type=int, default=10, help='max time horizon')
    parser.add_argument('--act_sup_coef_min', type=float, default=0.01, help='min coef of action regularization')
    parser.add_argument('--act_sup_coef_max', type=float, default=0.1, help='max coef of action regularization')
    parser.add_argument('--act_sup_coef_decay', type=int, default=40000, help='number of episodes to decay action regularization')
    parser.add_argument('--num_iterations', type=int, default=2000, help='number of MAPPO pretrain iterations')
    parser.add_argument('--save_every', type=int, default=2000, help='save pretrain models every x iterations')
    parser.add_argument('--num_games', type=int, default=5, help='number of games in a MAPPO pretrain iteration')
    parser.add_argument('--num_task', type=int, default=5, help='number of opponent policies of a given game')
    parser.add_argument('--num_sample', type=int, default=10, help='number of plays of a given opponent policy')
    parser.add_argument('--load_pretrain_model', action='store_true', default=False, help='whether load pretrained model')
    parser.add_argument('--row_max_for_state_emb', type=int, default=20, help='row for grid map')
    parser.add_argument('--column_max_for_state_emb', type=int, default=20, help='row for grid map')
    parser.add_argument('--max_time_horizon_for_state_emb', type=int, default=20, help='max time horizon for  state emb')
    parser.add_argument('--load_graph_emb_model', action='store_false', default=True, help='whether load graph emb model')
    parser.add_argument('--pool_size', type=int, default=1000, help='number of games in the pool')
    parser.add_argument('--base_rl', type=str, default='grasper_mappo', help='mappo, grasper_mappo')
    parser.add_argument('--edge_probability', type=float, default=0.8, help='edge_probability')
    parser.add_argument('--min_evader_pth_len', type=int, default=6, help='column for grid map')
    parser.add_argument('--use_act_supervisor', action='store_true', default=False, help='whether use HMP')
    parser.add_argument('--use_emb_layer', action='store_true', default=False, help='whether use observation embedding layer')
    parser.add_argument('--use_augmentation', action='store_true', default=False, help='concat. game config embed with state')
    parser.add_argument('--use_end_to_end', action='store_false', default=False, help='end-to-end training of whole network architecture')
    parser.add_argument('--h_init', type=str, default='unif', help='kaim, unif, xavi')
    parser.add_argument('--checkpoint', type=int, default=0, help='checkpoint')

    parser.add_argument('--num_test_games', type=int, default=30, help='number of games for testing')
    parser.add_argument('--ind_thd_min', type=float, default=-1.0, help='min threshold for ind games selection')
    parser.add_argument('--ind_thd_max', type=float, default=1.0, help='max threshold for ind games selection')
    parser.add_argument('--ood_thd_min', type=float, default=-1.0, help='min threshold for OOD games selection')
    parser.add_argument('--ood_thd_max', type=float, default=1.0, help='max threshold for OOD games selection')
    parser.add_argument('--pretrain_model_iteration', type=int, default=2000, help='checkpoint model iterations')
    parser.add_argument('--psro_iteration', type=int, default=int(3), help='iteration number of psro')
    parser.add_argument('--eval_episode', type=int, default=int(200), help='number for meta-game payoff estimation')
    parser.add_argument('--train_evader_number', type=int, default=int(200), help='number of best response training')
    parser.add_argument('--train_pursuer_number', type=int, default=int(50), help='number of best response training')
    parser.add_argument('--pursuer_runner_type', type=str, default="grasper_mappo", help='mappo, grasper_mappo, random')
    parser.add_argument('--load_graph_emb_model_in_psro', action='store_false', default=True, help='load graph emb model in psro')
    parser.add_argument('--ood_test', action='store_true', default=False, help='whether test OOD games')

    return parser.parse_args()